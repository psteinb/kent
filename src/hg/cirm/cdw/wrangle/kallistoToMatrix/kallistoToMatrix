#!/usr/bin/env python2.7

# a converter for kallisto output files
# parses ~800 cells in 1-2 minutes
# and merges everything into a single matrix that can be read with one line in R
# also outputs a binary hash files that can be read from python with one line

import logging, sys, optparse, gzip, gc
from collections import defaultdict
from os.path import join, basename, dirname, isfile, isdir, splitext
import os, marshal, glob
from multiprocessing.dummy import Pool as ThreadPool

# no garbage collection needed in here
gc.disable()

# the column of the kallisto output file with the TPM value
tpmColumnIndex = 4

# === command line interface, options and help ===
def parseArgs():
    parser = optparse.OptionParser("""usage: %prog [options] dirName
    outBase - collect expression counts from all abundance.tsv files,
    given a directory containing kallisto output sub-directories.

    Input files that end with "*.abundance.tsv" can be located either 
    directly in dirName or one level beneath it.

    TPM transcript counts are written to <outBase>.tpm.tab
    TPM gene counts are written to <outBase>.geneTpm.tab

    Also parses .log files with kallisto output and creates a .tab file
    that contains two basic stats, number of reads per file and number of
    reads mapped to transcript models, written to <outBase>.stat.tab
    Can be used for tagStormJoinTab.

    Ctrl-c does not work for this program. Do ctrl-z and then 'kill %%'.

    Example:
    kallistoToMatrix /hive/groups/cirm/submit/quake/quakeBrainGeo1/kallistoOut quakeBrainGeo1 -t 20
    """)

    parser.add_option("-d", "--debug", dest="debug", action="store_true", help="show debug messages")
    parser.add_option("-t", "--threads", dest="threads", action="store", type="int", help="number of threads to use, default %default", default=10)
    #parser.add_option("-g", "--geneLevel", dest="geneLevel", action="store_true", help="map transcripts to gene symbols and write the sum of all transcript TPMs into a file <outBase>.geneTpm.tab")
    parser.add_option("", "--transFile", dest="transFile", action="store", help="the text file with the mapping transcript-gene-symbol (sym is not used), one per line. default %default", default="/hive/data/outside/gencode/release_22/transToGene.tab")
    (options, args) = parser.parse_args()
    if args==[]:
        parser.print_help()
        exit(1)


    if options.debug:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    return args, options

# ==== functions =====
    
def findInputFiles(dirname):
    """ return two lists: cellIds and all paths of files */abundance.tsv in subdirs under dirname 
    subDir name is the cellId.

    alternative input:
    dirName can also be a directory full of *.abundance.tsv files where * is the cellId.
    """
    cellIds = []
    filePaths = []
    for inputPath in glob.glob(join(dirname, "*")):
        # check if it's an abundance file
        if inputPath.endswith(".abundance.tsv") and isfile(inputPath):
            cellId = basename(inputPath).split(".")[0]
            filePath = inputPath
        else:
            # check if it's a dir with the right filename in it
            if not isdir(filePath):
                continue
            filePath = join(filePath, "abundance.tsv")
            if not isfile(filePath):
                continue
            cellId = basename(inputPath)
        cellIds.append(cellId)
        filePaths.append(filePath)
    return cellIds, filePaths

def parseKallisto(fname):
    """ parse a kallisto abundance.tsv file, return dict transcriptId -> est_tpm 
    Does not return a value for transcripts where est_tpm is 0
    """

    logging.debug("parsing %s" % fname)
    ifh = open(fname)
    ifh.readline()

    d = {}
    for line in ifh:
        fs = line.rstrip("\n").split("\t")
        if fs[tpmColumnIndex]!="0":
            d[fs[0]] = float(fs[tpmColumnIndex])
    return d
        
def parseDict(fname, stripDot=False):
    " open (gzip) file with key-val one per line and return as dict "
    if fname.endswith(".gz"):
        ifh = gzip.open(fname)
    else:
        ifh = open(fname)

    ret = {}
    for line in ifh:
        if line.startswith("#") or line.startswith("transcriptId"):
            continue
        fs = line.rstrip("\n").split()
        transId = fs[0]
        geneId = fs[1]
        assert("T" in transId) # Ensembl transcript identifiers always have a T in them
        assert("G" in geneId)  # Ensembl gene identifiers always have a G in them
        if stripDot:
            transId = transId.split('.')[0]
            geneId = geneId.split('.')[0]
        ret[transId]=geneId
    return ret
        
def outputBigMatrix(cellNames, results, outFname, isGene=False):
    """
    given a list of cellNames and a list of transcript -> count dictionaries,
    write out a matrix with transcript -> counts in columns
    """
    logging.info("Writing data to file %s" % outFname)
    ofh = open(outFname, "w")
    # write header
    if isGene:
        ofh.write("#gene\t%s\n" % "\t".join(cellNames))
    else:
        ofh.write("#transcript\t%s\n" % "\t".join(cellNames))
    
    # create a sorted list of all transcript names
    logging.info("Getting transcript IDs")
    allTrans = set()
    for res in results:
        allTrans.update(res)
    allTrans = list(allTrans)
    allTrans.sort()

    # write out matrix
    logging.info("Iterating over transcript IDs and writing to tab file")
    for trans in allTrans:
        ofh.write("%s\t" % trans)
        row = []
        for countDict in results:
            row.append(str(countDict.get(trans, 0)))
        ofh.write("\t".join(row))
        ofh.write("\n")
    ofh.close()

    # also output as a binary file for now
    # it's a lot easier and faster to parse, at least for python scripts
    # can be read from python with a single line:
    # matrix = marshal.load(open("data.tab.marshal"))
    # matrix is then a nested hash: cellName -> transcript -> count
    binPath = outFname+".marshal"
    logging.info("Writing %s" % binPath)
    allData = {}
    for name, transDict in zip(cellNames, results):
        allData[name] = transDict
    marshal.dump(allData, open(binPath, "wb"))
        
# this was a try to write sparse matrices. 
# it results in smaller data files, but they are harder to compress with gzip
# overall the non-sparse matrices were smaller on the quake dataset

#def outputBigMatrixSparse(names, results, outFname):
    #logging.info("Writing data to file %s" % outFname)
    #ofh = open(outFname, "w")
    
    # create set of all transcript names
    #allTrans = set()
    #for res in results:
        #allTrans.update(res)

    # create dict with transcript -> number
    # and write out this mapping
    #ofh.write("#")
    #transToId = {}
    #for i, trans in enumerate(allTrans):
        #transToId[trans] = i
        #ofh.write("#%s=%d\n" % (trans, i))

    # write out matrix
    #for cellId, transDict in zip(names, results):
        #ofh.write("%s\t" % cellId)
        #strList = ["%d=%f" % (transToId[trans], val) for trans, val in transDict.iteritems()]
        #ofh.write(",".join(strList))
        #ofh.write("\n")
    #ofh.close()
    
def sumTransToGene(transDictList, transFile):
    """ given a list of dict transcript -> tpm, and a map transcript -> gene,
    map all transcripts to genes and return a list of gene -> sum of tpms
    If we have no gene ID, drop the transcript entirely.
    """
    transToGene = parseDict(transFile, stripDot=True)
    logging.info("Mapping %d transcript IDs to gene IDs" % len(transToGene))

    newRes = []
    noMapTransIds = set()
    for transCounts in transDictList:
        geneCounts = defaultdict(float)
        for transId, count in transCounts.iteritems():
            transId = transId.split(".")[0]
            geneId = transToGene.get(transId)
            if geneId is None:
                noMapTransIds.add(transId)
            else:
                geneCounts[geneId]+=count
        newRes.append(dict(geneCounts))

    logging.info("no gene ID found for %d transcript IDs. These are probably scaffolds/patches/etc. Example IDs: %s" %
        (len(noMapTransIds), list(noMapTransIds)[:5]))
    return newRes
    
def writeStats(inDir, outFname):
    """
    search for all .log files in inDir. Use the basename of these files
    as the cell ID and write a .tab file that can be joined with tagStormJoinTab
    """
    ofh = open(outFname, "w")
    ofh.write("meta\tkallistoProcReads\tkallistoAlnReads\tkallistoEstFragLen\n")

    inFnames = glob.glob(join(inDir, "log", "*.log"))
    print("Parsing %d logfiles and writing to %s" % (len(inFnames), outFname))
    for inFname in inFnames:
        cellId = basename(inFname).split(".")[0].split("_")[0]
        # [quant] processed 1,836,518 reads, 636,766 reads pseudoaligned
        # [quant] estimated average fragment length: 251.99
        for line in open(inFname):
            if line.startswith("[quant] processed "):
                words = line.split()
                readCount = words[2].replace(",","")
                alignCount = words[4].replace(",","")
            if line.startswith("[quant] estimated average fragment length:"):
                fragLen = line.split()[5]
        row = [cellId, readCount, alignCount, fragLen]
        ofh.write("\t".join(row)+"\n")
    ofh.close()

def main():
    args, options = parseArgs()
    inDir = args[0]
    outBase = args[1]

    transOutFname = outBase+".tpm.tab"
    statOutFname = outBase+".stat.tab"

    writeStats(inDir, statOutFname)

    cellNames, inFnames = findInputFiles(inDir)
    assert(len(cellNames)==len(inFnames))

    if len(inFnames)==0:
        logging.info("No input files found")
        sys.exit(1)
    logging.info("Found %d kallisto input files (*.abundance.tsv)" % len(inFnames))

    threadCount = options.threads
    logging.info("Using %d threads to parse input files" % threadCount)

    # multithreading in 4 lines
    pool = ThreadPool(threadCount)
    results = pool.map(parseKallisto,inFnames)
    pool.close()
    pool.join()

    logging.info("Done reading input files.")

    outputBigMatrix(cellNames, results, transOutFname)

    geneOutFname = outBase+".geneTpm.tab"
    results = sumTransToGene(results, options.transFile)
    outputBigMatrix(cellNames, results, geneOutFname, isGene=True)

main()
