#!/usr/bin/env python

# A little CGI interface to download the tables for a set of tracks via udr 
# to local machine. This is mostly useful when setting up a mirror or a VM
# of the browser. It does not run on hgwdev.

# This script does the following:
# - get trackDb and grp table from hgDownload
# - get table and gbdb sizes from ucsc rsync server
# - get list with track<->filename for all bigfile tracks from hgwdev
# - try to assign table names to gbdb files using this list and some hacky rules
# - parse hg.conf to find mysql server and hide a few tracks in its trackDb
# - infer track/subtrack hierarchy by parsing trackDb
# - generate HTML table with labels/sizes/tablecounts for all tracks and their child tracks
# - when user clicks submit, start udr transfer and redirect to page that shows progress
# - handles non-existing tables and some hgFixed tables

# When run from the command line, this CGI hides some tracks and removes from tracks from
# track search on hg19. This is usually run from a cronjob after trackDb updates.

# This script requires the following setup
# - mysqldb python module
# - "rsync" in path
# - "at" in path
#   To allow this on ubuntu, add these lines to /etc/sudoers:
#www-data     ALL = (mysql:mysql) NOPASSWD: /bin/ls,/usr/bin/rsync,/bin/rm
#www-data     ALL = (root:root) NOPASSWD: /bin/mkdir /gbdb
#www-data     ALL = (root:root) NOPASSWD: /bin/chown www-data.www-data /gbdb</pre>
# - the apache user has to be able to run 'at' jobs. 
#   To allow this on ubuntu, need to run this command to remove www-data from /etc/at.deny
#     sudo sed -i s/www-data//g /etc/at.deny

# This script does not handle:
# tables joined to other tables are not downloaded. Would have to parse all.joiner for that.

# format python errors in html, as we're a CGI script
import cgi
import cgitb; cgitb.enable()

# these are default python modules on python 2.7, no errors expected here
import urllib, urllib2, zlib, collections, StringIO, gzip, string, sys, os, random, \
    subprocess, re, types, socket

from collections import defaultdict, namedtuple
from os.path import *
from distutils import spawn

# this module has to be installed with one of these commands:
# - many common linuxes: pip install mysqldb
# - debian: sudo apt-get install python-mysqldb
# - fedora/centos/redhat: sudo yum install python-mysqldb
# The script works without the mysqldb module but cannot auto-hide some tracks.
mysqlDbLoaded = True
try:
    import MySQLdb
except:
    mysqlDbLoaded = False

# default mysql data dir on debian-based distros
MYSQLDIR = "/var/lib/mysql"

# can probably autodetect this, but hardcoded here
APACHEUSER = "www-data"

# optional file with rows to add to tableList
TABLELISTADD = "/root/tableListAdd.hg19.tab"

#DEBUG=True
DEBUG=False

# list of tables to exclude from track search
REMOVESEARCH = ["wgEncodeGencodeBasicV19", "wgEncodeGencodeCompV17", "wgEncodeGencodeBasicV14", "wgEncodeGencodeBasicV17", "wgEncodeGencodeCompV14", "mgcFullMrna", "wgEncodeGencodeBasicV7", "orfeomeMrna", "wgEncodeGencodePseudoGeneV14", "wgEncodeGencodePseudoGeneV17", "wgEncodeGencodePseudoGeneV19", "wgEncodeGencodeCompV7", "knownGeneOld6", "geneReviews", "transMapAlnSplicedEst", "gbCdnaInfo", "oreganno", "vegaPseudoGene", "transMapAlnMRna", "ucscGenePfam", "qPcrPrimers", "transMapAlnUcscGenes", "transMapAlnRefSeq", "genscan", "bacEndPairs", "fosEndPairs"]

# list of tracks to hide by default
FORCEHIDE = ["intronEst", "cons100way", "cons46way", "ucscRetroAli5"]

# always copy these (small) tables for the current db, if they exist
FORCETABLES = ['cytoBand', 'chromInfo', 'cytoBandIdeo', 'kgColor', \
    'knownGene', 'kgXref', 'ensemblLift', 'ucscToEnsembl','wgEncodeRegTfbsCells', \
    'tableList', 'refSeqStatus', 'wgEncodeRegTfbsCellsV3', 'extFile', 'trackDb', 'grp',
    'ucscRetroInfo5', "refLink", "ucscRetroSeq5", "ensemblLift", "knownCanonical",
    # for faster searches
    'hgFindSpec', 'ensemblToGeneName', "ucscToINSDC",
    # these are almost required for searches, common tracks and not too big
    "ensGene", "xenoRefGene"
    ]

# always copy these hgFixed tables
FORCEFIXED = ['trackVersion', 'tableList']

# big file table base URL
# points to a http directory with <db>/bigFiles.tab files that tell us which bigfile goes to which track
BIGFILETABLEURL = "http://hgwdev.soe.ucsc.edu/~max/browserbox/%s/bigFiles.tab.gz" # %s == db
#BIGFILETABLEURL = "http://hgdownload.cse.ucsc.edu/goldenpath/%s/database/bigFiles.tab.gz"

# cache of hg.conf dict
hgConf = None

def parseConf(fname):
    " parse a hg.conf style file, return as dict key -> value (all strings) "
    conf = {}
    for line in open(fname):
        line = line.strip()
        if line.startswith("#"):
            continue
        elif line.startswith("include "):
            inclFname = line.split()[1]
            if isfile(inclFname):
                inclDict = parseConf(inclFname)
                conf.update(inclDict)
        elif "=" in line: # string search for "="
            key, value = line.split("=")
            conf[key] = value
    return conf


def parseHgConf():
    """ return hg.conf as dict key:value """
    global hgConf
    if hgConf is not None:
        return hgConf

    hgConf = dict() # python dict = hash table

    confDir = dirname(__file__)
    fname = join(confDir, "hg.conf")
    hgConf = parseConf(fname)

    return hgConf

def sqlConnect(db, name):
    """ connect to sql """
    if name=="public":
        host, user, passwd = "genome-mysql.cse.ucsc.edu", "genomep", "password"
    elif name=="local":
        cfg = parseHgConf()
        host, user, passwd = cfg["db.host"], cfg["db.user"], cfg["db.password"]
    conn = MySQLdb.connect(host=host, user=user, passwd=passwd, db=db)
    return conn

def debug(msg):
    if DEBUG:
        print(msg+"<br>")
        sys.stdout.flush()

def runningAtUcsc():
    if "hgwdev" in socket.gethostname():
        return True
    return False
    
def runCmd(cmd, mustRun=True):
    " wrapper around os.system that makes sure sudo is not called "
    if runningAtUcsc() and cmd.startswith("sudo"):
        return 0

    ret = os.system(cmd)
    if ret!=0 and mustRun:
        print "Could not run command %s" % cmd
        sys.exit(0)
    return ret

def loadGroups(db):
    """ load grp table via mysql and return as a list of tuples (name, label)"""
    groups = []
    if mysqlDbLoaded:
        conn = sqlConnect(db, "public")
        cur = conn.cursor()
        cur.execute("SELECT name, label from grp order by priority")
        groups = []
        for row in cur.fetchall():
            groups.append((row[0], row[1]))
        cur.close()
        conn.close()
    else:
        for row in downloadTable(db, "grp"):
            groups.append((row[0], row[1]))
    return groups

def downloadTable(db, table):
    """
    download table from hgdownload by parsing sql file first to get the field
    names, then the tab sep file. Returns a list of objects, with field names
    as attributes and their values from the tab sep file.
    """
    baseUrl = 'http://hgdownload.cse.ucsc.edu/goldenPath/%s/database/' % db

    # parse the .sql file and create a namedtuple "struct" for it
    sqlUrl = baseUrl+table+".sql"
    sqlLines = urllib2.urlopen(sqlUrl).read().splitlines()
    fieldNames = []
    for l in sqlLines:
        if l.strip().startswith("PRIMARY KEY"):
            continue
        if l.startswith("  "):
            fieldName = l.split()[0].strip("`")
            fieldNames.append(fieldName)
    Struct = namedtuple("rec", fieldNames)

    # read the tab-sep data
    # can use a cached copy from /tmp
    tmpFname = "/tmp/"+db+"."+table+".txt.gz"
    if isfile(tmpFname):
        data = open(tmpFname)
    else:
        dataUrl = baseUrl+table+".txt.gz"
        remoteData = urllib2.urlopen(dataUrl).read()
        data = StringIO.StringIO(remoteData) # gunzipping requires to wrap a pseudo-file around the gzip data
        # write to cache file
        tmpFh = open(tmpFname, "w")
        tmpFh.write(remoteData)
        tmpFh.close()
    data = gzip.GzipFile(fileobj=data).read()
    data = data.replace("\\\n", "\a") # translate escaped mysql newline to \a
    data = data.replace("\\\t", "\b") # translate escaped mysql tab to \b
    lines = data.split("\n")

    # convert tab-sep lines to namedtuples (=objects)
    rows = []
    for line in lines:
        if len(line)==0:
            continue
        fields = line.split("\t")
        fields = [f.replace("\a", "\n").replace("\b", "\t") for f in fields]
        row = Struct(*fields)
        rows.append(row)

    return rows

def parseRa(text):
    " parse ra-style string and return as dict name:value "
    lines = text.split("\n")
    data = dict()
    for l in lines:
        if len(l)==0:
            continue
        key, val = string.split(l, " ", maxsplit=1)
        data[key] = val
    return data

def getParent(settingDict):
    """ given a dict key -> value from trackDb, return the 'parent' of a track, either the
    parent or superTrack or subTrack names

    This is really confusing...
    """
    parent = None
    # subTrack is like "parent"
    if "subTrack" in settingDict:
        # "parent <trackName> on"
        # remove the "on" part 
        parent = settingDict.get("subTrack")
        parent = parent.split()[0]

    if "parent" in settingDict:
        # "parent <trackName> on"
        # remove the "on" part 
        parent = settingDict.get("parent")
        parent = parent.split()[0]

    elif "superTrack" in settingDict:
        parent = settingDict.get("superTrack")
        parent = parent.split()[0]
        if parent=="on": # ignore "superTrack on" lines
            parent = None

    return parent

def getTrackVis(settings):
    trackVis= "hide" # default vis is hide
    if "visibility" in settings:
        vis = settings["visibility"]
        trackVis= vis

    # the order is important: tracks can have both superTrack <parent> <vis>
    # AND visibility <vis>. superTrack has prority, see wgEncodeRegMarkH3k27ac

    # visibiltiy can be expressed with
    # superTrack <parent> dense
    # or
    # visibility dense
    # 
    # superTrack on 
    # implies visibility hide
    isSuperTrack = False
    if "subTrack" in settings:
        opts = settings["subTrack"].split()
        if opts[-1]=="on":
            trackVis = "full"

    if "parent" in settings:
        opts = settings["parent"].split()
        if opts[-1]=="on":
            trackVis = "full"

    if "superTrack" in settings:
        opts = settings["superTrack"].split()
        if opts[0]=="on":
            isSuperTrack = True
            if len(opts)==1:
                trackVis= "hide"
            elif opts[1]=="show":
                trackVis= "full"
            else:
                assert(False)
        elif len(opts)==2:
            trackVis = opts[1]
        elif len(opts)==1:
            isSuperTrack = True
            trackVis = "hide"
        else:
            assert(False)
    return trackVis, isSuperTrack

def parseTrackDb(db):
    """ download and parse trackDb, returns 7 values
    1) dict trackName -> shortLabel
    2) dict trackName -> tableName (usually the same as trackName, but not for encode and genbank)
    3) dict trackName -> trackName of parent track
    4) dict group -> list of top-level trackNames (not table names)
    5) pseudoTracks: set of names of tracks that have no tables ("views", "composites", "superTracks", "container multiWig")
    6) trackVis: dict trackName -> visibility
    7) set of all superTrack names
    """
    rows = downloadTable(db, "trackDb")
    trackLabels = dict()
    trackParents = dict()
    trackTables = dict()
    groups = defaultdict(list)
    pseudos = set()
    trackVis = dict()
    superTracks = set()

    for row in rows:
        track = row.tableName
        shortLabel = row.shortLabel
        settings = parseRa(row.settings)
        # get visibility
        trackVis[track], isSuperTrack = getTrackVis(settings)
        if isSuperTrack:
            superTracks.add(track)
        # a track has no associated table if:
        # - it defines any view with "view xxx"
        # - it sets "compositeTrack on"
        # - it sets "superTrack on"

        if      "view" in settings or \
                settings.get("compositeTrack","")=="on" or \
                settings.get("container","")=="multiWig" or \
                isSuperTrack:
            pseudos.add(track)
            isPseudo = True
        else:
            isPseudo = False

        parent = getParent(settings)
        if parent!=None:
            trackParents[track] = parent
        else:
            group = settings.get("group")
            groups[group].append(track)

        trackLabels[track] = shortLabel

        if "table" not in settings:
            tableName = track
        else:
            tableName = settings["table"]

        if not isPseudo:
            trackTables[track] = tableName
    return trackLabels, trackTables, trackParents, groups, pseudos, trackVis, superTracks

def htmlHeader():
    " print start of page "
    print """
<html>
<head>
<title>UCSC Genome Browser mirror tool</title>

<script type='text/javascript' SRC='../js/jquery.js'></script>
<script type='text/javascript' SRC='../js/jquery.plugins.js'></script>
<link rel="stylesheet" href="../style/HGStyle.css" type="text/css" />
<link rel='stylesheet' href='../style/nice_menu.css' type='text/css' />

</head>
<body>
    """
    print open("../htdocs/inc/globalNavBar.inc").read()
    sys.stdout.flush()

def htmlFooter():
    " print end of page "
    print """
</body>
</html>
    """

def findTopParent(trackParents, trackName):
    " recursively search for the top level parent of a track "
    if trackName not in trackParents:
        return trackName
    return findTopParent(trackParents, trackParents[trackName])

def makeTrackHierarchy(trackParents):
    """ given a dict with track->parent return dict with parent->list of child tracks.
    """
    debug("hierarchy")
    trackChildren = dict()
    for track, parent in trackParents.iteritems():
        if parent not in trackChildren:
            trackChildren[parent] = []
        trackChildren[parent].append(track)
    return trackChildren

def getAllChildren(trackName, trackChildren):
    """ given track name and hierarchy info, return list of all children  (recursive)
    
    """
    if trackName not in trackChildren:
        return []
    children = trackChildren[trackName]
    assert(type(children) is types.ListType)

    tracks = []
    tracks.extend(children)
    for child in children:
        grandkids = getAllChildren(child, trackChildren)
        tracks.extend(grandkids)
    return tracks

def getTableInfo(trackName, trackTables, trackChildren, tableSizes):
    " return list of table names (including children) for a track and the total remote size "
    subTracks = getAllChildren(trackName, trackChildren)
    subTracks.append(trackName)
    trackTableNames = set([trackTables[t] for t in subTracks if t in trackTables])
    tableSizes = [tableSizes[n] for n in trackTableNames]
    totalSize = sum(tableSizes)
    return list(trackTableNames), totalSize

def humanReadable(totalSize):
    " convert number to human readable string, adding MB/kb etc "
    mbyte = 1024*1024
    gbyte = mbyte*1024
    tbyte = gbyte*1024
    if totalSize>tbyte:
        sizeStr = "%d TB" % (totalSize/tbyte)
    elif totalSize>gbyte:
        sizeStr = "%d GB" % (totalSize/gbyte)
    elif totalSize>mbyte:
        sizeStr = "%d MB" % (totalSize/mbyte)
    elif totalSize>1024:
        sizeStr = "%d kb" % (totalSize/1024)
    else:
        sizeStr = "%d bytes" % (totalSize)
    return sizeStr

#def freespace(p):
    #""" Returns the number of free bytes on the drive that p is on """
    # does not make a lot of sense in virtual box, with a virtual disk that is auto-extending
    #s = os.statvfs(p)
    #return s.f_bsize * s.f_bavail

def trackToFiles(trackName, trackTables, trackChildren, tableSizes, tableToGbdbFiles, noTableTracks):
    " return list of mysql tables and gbdb files for a given trackName "
    tableNames = []
    gbdbFiles = []

    trackTableNames, totalSize = getTableInfo(trackName, trackTables, trackChildren, tableSizes)
    for table in trackTableNames:
        if table in noTableTracks:
            continue
        tableNames.append(table)

        for gbdbFname in tableToGbdbFiles[table]:
            if trackName=="defaultConsTables" and (gbdbFname.endswith(".maf") or gbdbFname.endswith(".wib")):
                continue
            gbdbFiles.append(gbdbFname)

    return tableNames, gbdbFiles

def makeTableFileList(jobId, db, trackNames, trackTables, trackChildren, tableToGbdbFiles, tableSizes, forceTables, noTableTracks):
    """
    create an rsync include file in /tmp for a list of tracks and return file name

    special handling for "defaultConsTables"
    """
    outFname = "/tmp/%s_mysql_filesToDownload.txt" % jobId
    mysqlListFh = open(outFname, "w")
    gbdbListFname = "/tmp/%d_gbdb_filesToDownload.txt" % jobId
    gbdbListFh = open(gbdbListFname, "w")

    # write table and gbdb files names to two different files, one for mysql rsync, one for gbdb rsync
    for trackName in trackNames:
        tableNames, gbdbFiles = trackToFiles(trackName, trackTables, trackChildren, tableSizes, \
                tableToGbdbFiles, noTableTracks)

        for table in tableNames:
            for ext in [".MYD", ".MYI", ".frm"]:
                mysqlListFh.write("%s%s\n" % (table,ext))

        for gbdbFname in gbdbFiles:
            gbdbListFh.write(gbdbFname+"\n")

    # add the db twobit file and the trackDb index
    gbdbListFh.write("%s.2bit\n" % db)
    gbdbListFh.write("html/description.html\n")
    gbdbListFh.write("trackDb.ix\n")
    gbdbListFh.write("trackDb.ixx\n")

    # add some special tables that are always good to have
    for table in forceTables:
        for ext in [".MYD", ".MYI", ".frm"]:
            mysqlListFh.write("%s%s\n" % (table,ext))

    mysqlListFh.close()
    gbdbListFh.close()

    # same thing for files in hgFixed
    fixListFname = "/tmp/%d_hgFixed_filesToDownload.txt" % jobId
    ofh = open(fixListFname, "w")
    for table in FORCEFIXED:
        for ext in [".MYD", ".MYI", ".frm"]:
            ofh.write("%s%s\n" % (table,ext))
    ofh.close()

    return outFname, gbdbListFname, fixListFname

def printTrackInfo(db, trackName, trackTables, trackLabels, localSizes, trackChildren, tableSizes, \
            trackToGbdbFiles, gbdbSizes, showSubtracks, indent):
    " print info about one track as html "
    trackTableNames, remoteTableSize = getTableInfo(trackName, trackTables, trackChildren, tableSizes)

    gbdbSize, gbdbFnames = getGbdbSize(trackName, trackTableNames, trackToGbdbFiles, gbdbSizes)
    #print gbdbFnames,"<br>"

    # add note for omim/decipher/etc
    label = trackLabels[trackName]
    addHtml, addNote = "", ""
    remoteSize = remoteTableSize + gbdbSize

    if remoteSize==0:
        addHtml = 'disabled="disabled"'
        addNote = "<small>this track cannot be mirrored (restricted data)</small>"

    sizeStr = humanReadable(remoteTableSize)
    if len(trackTableNames)==1:
        tableStr = "%d table" % len(trackTableNames)
    else:
        tableStr = "%d tables" % len(trackTableNames)

    #print trackTableNames, gbdbFnames
    # sum up size of all child tracks and gbdb filenames on local disk
    #for t in trackTableNames:
        #print t, localSizes.get(t, 0), tableSizes.get(t, 0), "<br>"
    localTableSize = sum([localSizes.get(track, 0) for track in trackTableNames])
    localGbdbSize = sum([localSizes.get(fname, 0) for fname in gbdbFnames])
    #print localTableSize, localGbdbSize, "<br>"
    localSize = localTableSize + localGbdbSize
    debug("remoteTableSize %d, remote gbdb size %d, local table size %d, localGbdbSize %d" % \
        (remoteTableSize, gbdbSize, localTableSize, localGbdbSize))

    #print "remote, local", remoteSize, localSize, "<br>"
    status = ""
    isGrey = False
    if remoteSize!=0 and remoteSize<=localSize:
        addHtml = 'disabled="disabled"'
        isGrey = True
        status = ", downloaded"
    elif localTableSize != 0:
        status = ", partially downloaded"

    indentStr = ""
    if indent!=0:
        indentStr = "".join(indent*["&nbsp;&nbsp;&nbsp;"])

    gbdbSizeStr = humanReadable(gbdbSize)
    gbdbFCount = len(gbdbFnames)
    gbdbStr=""
    if gbdbFCount!=0:
        gbdbStr = " + %(gbdbFCount)d gbdb files, %(gbdbSizeStr)s" % locals()

    debug("tables: "+str(trackTableNames))
    debug("gbdbFiles: "+str(gbdbFnames))

    outStr = '%(indentStr)s<input type="checkbox" %(addHtml)s name="%(trackName)s" id="%(trackName)s">'\
        '<a href="hgMirror?db=%(db)s&showFiles=%(trackName)s">%(label)s</a> ' \
        '(<span>%(trackName)s</span>): %(tableStr)s, %(sizeStr)s%(gbdbStr)s%(status)s %(addNote)s<br>' % locals()
    if isGrey:
        outStr = '<span style="color:#C0C0C0">'+outStr+'</span>'
    print outStr

    indent += 1
    if showSubtracks:
        for subTrack in trackChildren.get(trackName, []):
            printTrackInfo(db, subTrack, trackTables, trackLabels, localSizes, trackChildren, \
                tableSizes, trackToGbdbFiles, gbdbSizes, \
                showSubtracks=showSubtracks, indent=indent)

def getGbdbSize(trackName, trackTableNames, trackToGbdbFiles, gbdbSizes):
    " sum up sizes of all files for all tables "
    # first get the list of fnames
    gbdbFnames = set()
    # some entries like "liftOver" have no mysql table
    if len(trackTableNames)==0:
        trackTableNames = [trackName]

    for table in trackTableNames:
        for gbdbFname in trackToGbdbFiles[table]:
            if trackName=="defaultConsTables":
                if gbdbFname.endswith(".maf") or gbdbFname.endswith(".wib"):
                    continue
            gbdbFnames.add(gbdbFname)

    # then their size
    total = 0
    for gbdbFname in gbdbFnames:
            size = gbdbSizes[gbdbFname]
            total += size
    return total, gbdbFnames

def htmlDropBox(selName, elList, selKey):
    """ 
    print html dropdown box with a selected default element and auto-reload on selection 
    print html dropbox box with (key, desc) elList, selKey is the key of the selected element.
    the name of the dropbox variable is selName and upon selection, a page refresh will be issued
    with the new value in selName
    """
    addStr = ""
    if selName=="clade":
        addStr += "document.orgForm.org.value = 0; "
    if selName=="org" or selName=="clade":
        addStr += "document.orgForm.db.value = 0; "

    print '''<SELECT NAME="%s" onchange="document.orgForm.%s.value = document.mainForm.%s.options[document.mainForm.%s.selectedIndex].value; %s document.orgForm.submit();">''' % (selName, selName, selName, selName, addStr)

    for row in elList:
        elKey, desc = row
        selStr = ""
        if elKey==selKey:
            selStr = " SELECTED"
        print '<OPTION%s VALUE="%s">%s</OPTION>' % (selStr, elKey, desc)
    print '</SELECT>'

def printHiddenForm(clade, org, db):
    " hidden form is needed for javascript "
    print """
    <FORM ACTION="hgMirror" METHOD="GET" NAME="orgForm">
    <input type="hidden" name="clade" value="%s">
    <input type="hidden" name="org" value="%s">
    <input type="hidden" name="db" value="%s">
    </FORM>
    """ % (clade, org, db)

def getCladeAssemblyDb(clade, org, db):
    """ return the list of clades, organisms and assemblies and default DBs.
    any of clade, org or db can be None.
    Return values for clade, org, db so all are valid strings
    """
    if not mysqlDbLoaded:
        print("<small>info: MySQLDb not installed, cannot retrieve hgcentral.dbDb, using internal defaults</small>")
        cladeList = [("mammal", "Mammal")]
        orgList = [("Human", "Human")]
        dbList = [("hg19", "Human (GrCh37)"), ("mm9", "Mouse (NCBI37)")]
        defaultDb = {"Human":"hg19"}
        orgInfo = {}
        orgInfo["clades"] = cladeList
        orgInfo["orgs"] = orgList
        orgInfo["dbs"] = dbList
        orgInfo["defaultDbs"] = {"Human":"hg19"}

        return orgInfo, "mammal", "Human", "hg19"

    conn = sqlConnect("hgcentral", "public")
    cur = conn.cursor()

    # list of all clades ("mammal", "Mammal"), ...
    cladeList = []
    cur.execute("SELECT name, label FROM clade ORDER BY priority")
    for row in cur.fetchall():
        cladeList.append((row[0], row[1]))

    # list of organisms for current clade, ("Human", "Human"), ("Chimp", "Chimp"), ...
    if clade is None or clade=="0":
        clade = "mammal"
    orgList = []
    cur.execute('SELECT genome FROM genomeClade WHERE clade=%s ORDER BY priority', (clade,))
    for row in cur.fetchall():
        orgList.append((row[0], row[0]))

    # list of assemblies of current organism, like ("hg19", "NCBI37"), ("hg18", NCBI36"), etc...
    if org is None or org=="0":
        org = orgList[0][0]
    dbList = []
    cur.execute('SELECT name, description FROM dbDb WHERE organism = %s order by orderKey;', (org, ))
    for row in cur.fetchall():
        dbList.append((row[0], row[1]))

    # default db per organism, {"Human":"hg19"}
    defaultDbs = {}
    cur.execute('SELECT genome, name FROM defaultDb')
    for row in cur.fetchall():
        defaultDbs[row[0]] = row[1]

    cur.close()
    conn.close()

    if (db==None or db=="0"):
        if org not in defaultDbs:
            print "organism %s is not valid" % org
            sys.exit(0)
        db = defaultDbs[org]

    # make sure that the db we return exists on public mysql
    if mysqlDbLoaded:
        import _mysql_exceptions
        try:
            conn  = sqlConnect(db, "public")
        except _mysql_exceptions.OperationalError:
            print("<small>error: DB %s does not exist on public sql server</small>" % db)
            db = "hg19"

    orgInfo = {}
    orgInfo["clades"] = cladeList
    orgInfo["orgs"] = orgList
    orgInfo["dbs"] = dbList
    orgInfo["defaultDbs"] = defaultDbs

    return orgInfo, clade, org, db

def htmlDbSelector(orgInfo, clade, org, db):
    " print dropdown boxes with clade, assembly, DBs and refresh when selected "
    print '<FORM name="mainForm">'

    print("Group: ")
    htmlDropBox("clade", orgInfo["clades"], clade)
    print("Genome: ")
    htmlDropBox("org", orgInfo["orgs"], org)
    print("Assembly: ")
    htmlDropBox("db", orgInfo["dbs"], db)

    print '<INPUT type="submit" name="submit" value="Select"></input>'
    print '</FORM>'

    printHiddenForm(clade, org, db)

def htmlTrackTable(db, trackLabels, trackTables, \
        trackParents, trackChildren, groupList, groupToTopTracks, \
        tableSizes, localSizes, gbdbSizes, trackToGbdbFiles, showSubtracks):
    " print list of track sizes/tablecount as a html form, sorted by group "

    myUrl = basename(__file__)

    print 'Locally mirrored tracks are faster to browse than tracks that are accessed through the internet.<br>'
    print 'Select any number of tracks from the list below and click "Download" when finished.<br>'
    print 'The data will be downloaded from the UCSC servers with udr/rsync and copied to the local mysql database and %s.<p>' % getGbdbDir()

    htmlStats(localSizes, gbdbSizes, tableSizes)

    print '<form action="%s" method="post">'  % myUrl
    print '<input type="submit" name="submit" value="Download"></input>'

    if showSubtracks:
        print '<a href="%s">hide subtracks and show predefined groups</a><br>' % myUrl
        del groupToTopTracks["special"]
    else:
        print '<a href="%s?showSubtracks=1">show subtracks</a><br>' % myUrl

    for groupName, groupLabel in groupList:
        # skip empty groups like custom
        if len(groupToTopTracks[groupName])==0:
            continue
        print "<h4>%s</h4>" % groupLabel

        for trackName in groupToTopTracks[groupName]:
            printTrackInfo(db, trackName, trackTables, trackLabels, localSizes, \
                trackChildren, tableSizes, trackToGbdbFiles, gbdbSizes, showSubtracks, 0)

    print '<p>'
    print '<input type="hidden" name="db" value="%s"></input>' % db
    print '<input type="submit" name="submit" value="Download"></input>'
    print '</form>'

def downloadCache(url, cacheFname):
    " download file from url or open local cached copy. Return list of lines "
    cachePath = "/tmp/"+cacheFname
    if isfile(cachePath):
        return open(cachePath).read().splitlines()

    try:
        data = urllib2.urlopen(url).read()
    except urllib2.HTTPError:
        print "<small>info: Could not find %s. bigWig/bigBed/bam files will be skipped.<br></small>" % url
        data = None

    if data is not None and url.endswith(".gz"):
        data = StringIO.StringIO(data) # gunzipping requires to wrap a pseudo-file around the gzip data
        data = gzip.GzipFile(fileobj=data).read()

    # only create cache file if we got some data
    if data == None:
        data = ""
    else:
        cacheFh = open(cachePath, "wb")
        cacheFh.write(data)
        cacheFh.close()

    return data.splitlines()

def linkTrackToGbdb(fnames, db, tableNames):
    """
    do some educated guessing on the gbdb files<->track links. returns a dict table -> file
    Needs a file bigFiles.tab.gz that assigns the bbi link table names to big files in them.

    fnames is a list of gbdb filenames that we try to assign somehow.
    """

    debug("linking trackDb")
    # download a list of trackname -> bigFile name from hgwdev
    # cannot do this on the fly
    lines = downloadCache(BIGFILETABLEURL % db, db+"_bigFiles.tab")
    tableFiles = defaultdict(list)
    assignedFnames = []
    fileTables = dict()
    for line in lines:
        table, fname = line.rstrip("\n").split("\t")
        if not fname.startswith("/gbdb"):
            # cannot get files on external http servers for internal tracks 
            continue
        else:
            fname = fname.replace("/gbdb/%s/" % db, "")
        tableFiles[table].append(fname)
        fileTables[fname] = table
        assignedFnames.append(fname)

    manualRules = [
        # format: regex in filename -> name of track
        (db+".2bit", "seq"),
        ("description.html", "seq"),
        ("gc5Base", "gc5Base"),
        ("multiz([0-9]+)way" , r'multiz\1way'),
        ("evoFold" , "evofold"),
        ("RNA-img" , "tRNAs"),
        ("Patch([0-9]+)" , r'altSeqComposite\1'),
        ("snp([0-9]+)Common" , r'snp\1Common'),
        ("snp([0-9]+)" , r'snp\1'),
        ("liftOver" , "liftOver"),
        ("cloneend" , "bacCloneEnds"),
        ("sts.11" , "stsMap"),
        ("kgTarget" , "knownGene"),
        ("fosEnds" , "fosEndPairs"),
        ("laminB1" , "laminB1"),
        ("hgmd" , "hgmdVar"),
        ("lrg.bb" , "lrg"),
        ("integrated_phase1" , "tgpPhase1"),
        ("HGDP" , "hgdpGeo")
        ]

    regexRules = []
    for regex, repl in manualRules:
        regexRules.append((re.compile(regex), repl))

    for fname in fnames:
        # assign bai files to their bam file table
        if fname.endswith(".ixx") or fname.endswith(".ix"):
            table = splitext(fname)[0]
            tableFiles[table].append(fname)
            assignedFnames.append(fname)
            continue

        if fname.endswith(".bai"):
            bamName = splitext(fname)[0]
            if bamName not in fileTables:
                debug("%s: bam file has index but is not used by any track" % bamName)
                continue

            table = fileTables[bamName] # if this fails, then a .bai file has no bam file
            tableFiles[table].append(fname)
            assignedFnames.append(fname)
            continue

        # check fname for regex and assign to some manually defined track

        for regex, repl in regexRules:
            match = regex.search(fname)
            if match != None:
               # transform matching string using regex
               matchStr = match.group()
               table = regex.sub(repl, matchStr)
               tableFiles[table].append(fname)
               assignedFnames.append(fname)
               #if "multiz100way" in fname:
                   #print fname, "<br>"
                   #print "table", table, "<br>"

    orphanFnames = set(fnames) - set(assignedFnames)
    for fname in sorted(orphanFnames):
        debug("unassigned gbdb file: "+fname)
    #print assignedFnames

    misassignedTables = set(tableFiles) - set(tableNames)
    for table in sorted(misassignedTables):
        debug("not existing table: "+table)
        debug("for files: "+",".join(tableFiles[table]))
    return tableFiles

def getRsyncSizes(dataType, db):
    """
    debug("rsync sizes")
    if dataType is "mysql: return dict with tableName:size for given db (includes indexes, frm + data)
    if dataType is "gbdb": return dict with filaname:size for given db
    """
    # run rsync command
    tmpFname = "/tmp/%s_%s.rsync.txt" % (dataType, db)
    if not isfile(tmpFname):
        cmd = "rsync -nav rsync://hgdownload.cse.ucsc.edu/%s/%s/ > %s" % (dataType, db, tmpFname)
        runCmd(cmd)

    # parse rsync output file
    tableSizes = collections.defaultdict(int)

    for line in open(tmpFname):
        ## rsync output looks like this:
        # receiving incremental file list
        # drwxr-xr-x     1875968 2013/11/23 23:37:59 .
        # -rw-rw-r--     2031084 2011/01/04 14:55:26 HInv.MYD
        fields = line.rstrip("\n").split()
        if len(fields)!=5:
            continue
        if fields[0][0]=="d":
            continue
        fileName = fields[-1]
        tableSize = int(fields[1])

        if dataType=="gbdb":
            resName = "%s" % (fileName)
        else:
            resName = fileName.split(".")[0]
        tableSizes[resName] += tableSize
    return tableSizes

#def getTableRelations(db):
    # a start to parse all.joiner
    # set hg hg16,hg17,hg18,hg19
    # identifier jkgTranscriptId
    # "Known genes 3 trancript identifier"
    #    $hg,$mm.jkgTxCdsRepick.name
    #    $hg,$mm.jkgTxInfo.name
    #    $hg,$mm.jkgTxCdsEvidence.name

    # 
    #assert(False) # not finished
    #sets = {}
    #ifh = open("all.joiner")
    #for line in ifh:
        #if line.startswith("set"):
            #fields = line.rstrip("\n").split()
            #var = fields[1]
            #targets = set(fields[-1].split(","))
            #resolvedTargets = []
            #for t in targets:
                #if t.startswith("$"):
                    #resolvedTargets.extend(sets[t[1:]])
                #else:
                    #resolvedTargets.append(t)
            #sets[var] = resolvedTargets

def udrIsUsable():
    " return true if we can use udr "
    # http://stackoverflow.com/a/12611523/233871
    # this is doing he same as the unix which command
    if spawn.find_executable("rsync") is None:
        print "ERROR: could not find the rsync executable in the PATH"
        sys.exit(0)

    # we temporarily don't use udr 
    return False

    # check if we can find udr binary
    udrPath = spawn.find_executable("udr")
    if udrPath is None:
        return False

    if not isfile("/tmp/useUdr"):
        # try to transfer a file
        cmd = "udr rsync -av hgdownload.soe.ucsc.edu::goldenPath/hg19/bigZips/README.txt /tmp/"
        ret = runCmd(cmd, mustRun=False)
        useUdr = (ret==0)
        open("/tmp/useUdr", "w").write(str(int(useUdr)))
        return useUdr

    useUdr = bool(int(open("/tmp/useUdr").read()))
    return useUdr

def buildRsyncCmd(remotePath, localPath, listFname, logFname):
    """ returns an rsync or udr command  to get files from remotePath to localPath"""
    if udrIsUsable():
        cmd =\
            'udr rsync -avz --no-progress --files-from=%(listFname)s ' \
            'hgdownload.cse.ucsc.edu::%(remotePath)s %(localPath)s >> %(logFname)s 2>&1\n' % locals()
    else:
        cmd =\
            'rsync -avz --no-progress --files-from=%(listFname)s ' \
            'rsync://hgdownload.cse.ucsc.edu/%(remotePath)s %(localPath)s >> %(logFname)s 2>&1\n' % locals()
    return cmd


def runRsyncJobs(jobId, db, listFname, gbdbListFname, fixedFname):
    " run rsync, redirect stdout and return the ID of the stdout log file "
    localDbDir = join(MYSQLDIR, db)
    localFixedDir = join(MYSQLDIR, "hgFixed")
    jobFname = "/tmp/%d.sh" % jobId
    logFname = "/tmp/%d.log" % jobId

    # write job script
    cmdFh = open(jobFname, "w")

    cmdFh.write("ps -o pgid= -p $$ > /tmp/lastJob.pid\n")

    cmd = "sudo -u mysql " + buildRsyncCmd("mysql/"+db, localDbDir, listFname, logFname)
    cmdFh.write(cmd)

    cmd = "sudo -u mysql " + buildRsyncCmd("mysql/hgFixed", localFixedDir, fixedFname, logFname)
    cmdFh.write(cmd)

    cmd = buildRsyncCmd("gbdb/"+db, getGbdbDir()+"/"+db, gbdbListFname, logFname)
    cmdFh.write(cmd)

    cmdFh.close()
    # "at" suggested by http://stackoverflow.com/questions/6024472/start-background-process-daemon-from-cgi-script/6091159#6091159
    cmd = "at now -M -f %s" % jobFname

    # write commands to log file
    logFh = open("/tmp/%d.log" % jobId, "w")
    logFh.write(open(jobFname).read())
    logFh.write("\nrsync output:\n")
    logFh.close()

    # write jobId to status file
    idFh = open("/tmp/lastJob.log", "w")
    idFh.write(str(jobId))
    idFh.close()

    # run commands
    print("Starting udr/rsync command script...")
    runCmd(cmd)

def refreshPage(paramStr, delay=5, addNote=False):
    " refresh current CGI page using javascript "
    newUrl = basename(__file__)+"?"+paramStr
    print """
    <script type="text/javascript">
    function Redirect()
        { window.location="%s"; }
    setTimeout('Redirect()', %d);
    </script>
    """ % (newUrl, delay)

    if addNote:
        print("""Redirecting to <a href="%s">%s</a>"""  % (newUrl, newUrl))

def jobsAreDone():
    " True if no jobs currently in the 'at' queue "
    cmd = "at -l | wc -l > /tmp/atWc.txt"
    runCmd(cmd)
    lineCount = int(open("/tmp/atWc.txt").read().strip())
    os.remove("/tmp/atWc.txt")
    return lineCount==0

def printLog(jobId):
    " print rsync log for given jobId to stdout "
    jobFname = "/tmp/%d.log" % int(jobId)
    print "rsync download commands:<p>"
    print "<pre>"
    if not isfile(jobFname):
        print "This download job is not active anymore.<p>"
        print '<a href="hgMirror">Start a new download</a>'
        sys.exit(0)

    for line in open(jobFname):
        print line,

    print "</pre>"
    if jobsAreDone():
        print '<a href="hgTracks">Back to genome browser</a><p>'
        print '<a href="hgMirror">Download more tracks</a>'
    else:
        print '<i>Downloading files... Page will reload every 4 seconds until download is complete.</i>'
        print '<i><a href="hgMirror?stopAllJobs=1">Cancel download now</a></i>'
        refreshPage("jobId=%d" % jobId, delay=4000, addNote=False)

def removeSomeTracksFromSearch(conn):
    cur = conn.cursor()
    for table in REMOVESEARCH:
        query = "DELETE FROM hgFindSpec WHERE searchTable='%s';" % table
        cur.execute(query)
    cur.close()

def hideSomeTracks(conn, localTables):
    """
    hide some notoriously slow tracks by default
    """
    if not mysqlDbLoaded:
        print "warning: cannot hide some tracks, module mysqldb not installed"
        return

    if "trackDb" not in localTables:
        return

    cur = conn.cursor()
    hideList = ["'"+s+"'" for s in FORCEHIDE]
    hideStr = ", ".join(hideList)
    hideStr = "(%s)" % hideStr
    query = "UPDATE trackDb SET visibility=0 WHERE tableName in %s" % hideStr
    cur.execute(query)
    cur.close()

def getGbdbDir():
    " return local gbdb dir without trailing slash "
    gbdbLoc = parseHgConf().get("gbdbLoc1", "/gbdb")
    gbdbLoc = gbdbLoc.rstrip("/")
    return gbdbLoc

def getLocalSizes(db):
    """
    return a dict with table name -> total size of a mysql directory and filename -> size for the gbdb dir
    (gbdb filenames are relative to the gbdb/db directory)
    """

    path = join(MYSQLDIR, db)
    sizes = defaultdict(int)
    if runningAtUcsc():
        return sizes

    sqlFname = '/tmp/localMysqlDirList.txt'
    cmd = 'sudo -u mysql /bin/ls -l %s > %s' % (path, sqlFname)
    ret = runCmd(cmd, mustRun=False)
    if ret!=0:
        print "<small>info: cannot read file sizes from %s, local file sizes unknown</small><br>" % path
        return sizes

    for line in open(sqlFname):
        fields = line.strip().split()
        if len(fields)<4:
            continue
        size = int(fields[4])
        fname = fields[-1]
        fileNoExt = splitext(basename(fname))[0]
        sizes[fileNoExt] += size
    if len(sizes)==0:
        print "(warning: local directory %s seems to be empty)" % path

    gbdbDir = join(getGbdbDir(), db)
    if isdir(gbdbDir):
        # get the size of all gbdb files
        gbdbFname = '/tmp/localGbdbDirList.txt'
        # trailing slash is important
        cmd = 'find %s/ -type f > %s ' % (gbdbDir, gbdbFname)
        runCmd(cmd)
        fnames = open(gbdbFname).read().splitlines()
        for fname in fnames:
            relName = fname.replace(gbdbDir+"/", "")
            sizes[relName] = getsize(fname)
    return sizes

def makeGbdb():
    """ create the gbdb directory and assign it to the apache user """
    if not isdir(getGbdbDir()):
        cmd = "sudo mkdir %s" % getGbdbDir()
        runCmd(cmd)
        cmd = "sudo chown %s.%s %s" % (APACHEUSER, APACHEUSER, getGbdbDir())
        runCmd(cmd)

def checkGbdbMysqlAccess():
    """ check if we have write access to gbdb and mysql dir and can run the at command """

    msg = """<pre>        www-data     ALL = (mysql:mysql) NOPASSWD: /usr/local/bin/udr,/bin/ls,/usr/bin/rsync,/bin/rm
        www-data     ALL = (root:root) NOPASSWD: /bin/mkdir /gbdb
        www-data     ALL = (root:root) NOPASSWD: /bin/chown www-data.www-data /gbdb</pre>
        """

    # check if we can write to gbdb
    tmpFname = "%s/test.tmp" % getGbdbDir()
    try:
        open(tmpFname, "w")
    except IOError:
        print "This program cannot write to the %s directory. Please make sure that the apache user has permission to write to %s<br>" % (getGbdbDir(), getGbdbDir())
        print 'Use "sudo visudo" to add these lines to /etc/sudoers:<br>'
        print msg
        print 'Or check the directory permissions if the directory already exists.<br>'
        sys.exit(0)

    # check if we can rsync to mysql
    tmpFname2= "%s/test.tmp" % MYSQLDIR
    cmd = "sudo -u mysql rsync %s %s" % (tmpFname, tmpFname2)
    ret = runCmd(cmd, mustRun=False)
    if ret!=0:
        print "Could not run %s<br>" % cmd
        print """Cannot run rsync as the mysql user. Please make sure that you have these lines in /etc/sudoers:<br>"""
        print msg
        sys.exit(0)

    # cleanup the two tmp files
    os.remove(tmpFname)

    cmd = "sudo -u mysql rm %s" % tmpFname2
    ret = runCmd(cmd, mustRun=False)
    if ret!=0:
        os.remove(tmpFname2)

    # check if we can run "at"
    cmd = "echo echo hi | at -M now"
    ret = runCmd(cmd, mustRun=False)
    if ret != 0:
        print "Could not run %s<br>" % cmd
        print "It looks like we cannot run the 'at' command<br>"
        print "You might have to remove %s from /etc/at.deny" % APACHEUSER
        sys.exit(0)

def findImportantTables(tableSet):
    """
    some tables are important for some assemblies, we always add them
    """
    tables = []
    for t in FORCETABLES:
        if t in tableSet:
            tables.append(t)
    return tables

def htmlStats(localSizes, gbdbSizes, tableSizes):
    locTotal   = humanReadable(sum(localSizes.values()))
    gbdbTotal  = humanReadable(sum(gbdbSizes.values()))
    tableTotal = humanReadable(sum(tableSizes.values()))
    print("<b>Total size at UCSC</b>: mysql tables %(tableTotal)s, gbdb files %(gbdbTotal)s<br>" % locals())
    print("Total size of tables and gbdb on local disk: %(locTotal)s<p>" % locals())

def addPredefined(trackVis, superTracks, groupList, groupToTopTracks, trackLabels, \
        trackChildren, tableToGbdbFiles, trackTables, tableSizes):
    """ add special predefined track groups in place, modifies the last five parameters 
        These groups are special "tracks" that don't exist, their children are the real tracks
    """
    # get all track that are not hidden
    defaultTracks = []
    for track, vis in trackVis.iteritems():
        if vis!="hide":
            defaultTracks.append(track)

    # go down the hierarchy and let "hide" on higher levels override the lower ones
    # remove all tracks that are somehow hidden by higher tracks from the first list
    defaultTracks = set(defaultTracks)
    for topTracks in groupToTopTracks.values():
        for topTrack in topTracks:
            if trackVis.get(topTrack, None)=="hide":
                for child in getAllChildren(topTrack, trackChildren):
                    if child in defaultTracks:
                        defaultTracks.remove(child)

    # also remove all superTracks from this list, otherwise will pull in all of encode again
    # somehow visibility/inheritance works this way
    defaultTracks = defaultTracks-set(superTracks)
    #print defaultTracks,"<br>"

    debug(",".join(defaultTracks))

    # create the two other sets of tracks, based on defaultTracks:
    defaultNoCons = []
    for t in defaultTracks:
        if "multiz" not in t and not t.startswith("cons"):
            defaultNoCons.append(t)

    nonEncode = []
    for track in trackVis:
        if track in defaultTracks or not track.startswith("wgEncode"):
            nonEncode.append(track)

    nonEncAllTables = [t for t in tableSizes.keys() if not t.startswith("wgEncode")]

    # we need lists, not sets
    defaultTracks = list(defaultTracks)

    groupList.insert(0, ("special", "Predefined tracks sets"))
    groupToTopTracks["special"] = ["defaultNoCons", "defaultConsTables", \
        "default", "nonEncode", "liftOver", "nonEncAllTables"]

    trackLabels["defaultNoCons"] = "Default tracks without conservation"
    trackLabels["defaultConsTables"] = "Default tracks with conservation tables, but no alignments"
    trackLabels["default"] = "Default tracks"
    trackLabels["nonEncode"] = "Default tracks plus all non-Encode tracks"
    trackLabels["liftOver"] = "Liftover files"
    trackLabels["nonEncAllTables"] = "All non-Encode database tables and tracks"

    trackChildren["defaultNoCons"] = defaultNoCons
    trackChildren["defaultConsTables"] = defaultTracks
    trackChildren["default"] = defaultTracks
    trackChildren["nonEncode"] = nonEncode

    trackChildren["nonEncAllTables"] = nonEncAllTables

    # hack: add the table names for non-track tables 
    for tn in nonEncAllTables:
        trackTables[tn] = tn

def stopAllJobs():
    """ stop all waiting at jobs and the currently running download job """
    cmd = "atrm `at -l | cut -f1`"
    runCmd(cmd)

    if isfile("/tmp/lastJob.pid"):
        lastPid = open("/tmp/lastJob.pid").read().strip()
        cmd = "sudo kill -- -%s" % lastPid
        runCmd(cmd)
    
def assertEmptyQueue():
    """ if the at queue is not empty, show link to log file of running job and stop program """
    if jobsAreDone():
        return

    jobId = open("/tmp/lastJob.log").read()
    print "There is still a download job running<br>"
    print '<a href="hgMirror?jobId=%s">Show download job</a>' % jobId
    sys.exit(0)

# the list of allowed chars in cgi args: digits, letters and dashes
legalChars = set(string.digits)
legalChars.update(set(string.letters))
legalChars.update("_-.()/: ")

def mustBeClean(str):
    """ make sure a string contains only letters and digits """
    if str==None:
        return str

    str = urllib.unquote(str)
    str = str.strip()

    for s in str:
        if s not in legalChars:
            print "illegal character in CGI parameter"
            sys.exit(0)
    return str

#def getDb(args, org):
    #""" get Db from either CGI args or hgcentral, makes sure that DB actually exists """
    #db = mustBeClean(args.getvalue("db", default=None))
    #if db=="0":
        #db = None
#
    #if db!=None:
        #if mysqlDbLoaded:
            #import _mysql_exceptions
            #try:
                #conn  = sqlConnect(db, "public")
            #except _mysql_exceptions.OperationalError:
                #print("<small>error: DB %s does not exist on public sql server</small>" % db)
                #db = None
    ##else:
        #if mysqlDbLoaded:
            #conn = sqlConnect("hgcentral", "public")
            #cur = conn.cursor()
            ## get default db for org
            #cur.execute('SELECT name from defaultDb where genome=%s', (org,))
            #rowList = cur.fetchall()
            #print rowList
            #db = rowList[0][0]
            #if db=="":
                #print "Invalid org parameter %s" % org
                #sys.exit(0)
    #else:
        #db = "hg19"
    #return db

def getCgiVar(args, name):
    return mustBeClean(args.getvalue(name, default=None))

def addTableList(db, conn):
    " add a local file with rows to add to tableList for hg19 "
    if db=="hg19" and isfile(TABLELISTADD):
        query = 'LOAD DATA INFILE "%s" INTO TABLE tableList' % (TABLELISTADD)
        cur = conn.cursor()
        cur.execute(query)
        cur.close()

def postRsyncChanges(db, localSizes):
    " remove some tracks from trackDb, others from hgFindSpec and add a few row to tableList"
    if not mysqlDbLoaded:
        return
    conn = sqlConnect(db, "local")
    hideSomeTracks(conn, localSizes)
    removeSomeTracksFromSearch(conn)
    addTableList(db, conn)
    conn.close()

def htmlMiddle(args):
    " print html middle part "

    clade = getCgiVar(args, "clade")
    org   = getCgiVar(args, "org")
    db    = getCgiVar(args, "db")
    orgInfo, clade, org, db = getCladeAssemblyDb(clade, org, db)

    if not "jobId" in args.keys():
        # parse trackDb
        debug("parsing")
        groupList = loadGroups(db)
        trackLabels, trackTables, trackParents, groupToTopTracks, noTableTracks, trackVis, superTracks = parseTrackDb(db)
        tableSizes = getRsyncSizes("mysql", db)
        trackChildren = makeTrackHierarchy(trackParents)
        gbdbSizes = getRsyncSizes("gbdb", db)
        tableToGbdbFiles = linkTrackToGbdb(gbdbSizes, db, tableSizes)

    # when user has clicked OK, run rsync and refresh with jobId
    if "submit" in args.keys() and args["submit"].value=="Download":
        if runningAtUcsc():
            print "<br>Cannot do this on hgwdev. Copying things from hgdownload to hgwdev is not a good idea."
            sys.exit(0)

        makeGbdb()
        checkGbdbMysqlAccess()

        trackList = set(args.keys())
        for t in trackList:
            mustBeClean(t)
        trackList.remove("submit")
        trackList.remove("db")

        forceTables = findImportantTables(tableSizes)

        jobId = int(random.random()*1000000)

        addPredefined(trackVis, superTracks, groupList, groupToTopTracks, trackLabels, trackChildren, \
            tableToGbdbFiles, trackTables, tableSizes)

        listFname, gbdbFname, fixedFname = makeTableFileList(jobId, db, trackList, trackTables, trackChildren, \
                                        tableToGbdbFiles, tableSizes, forceTables, noTableTracks)
        runRsyncJobs(jobId, db, listFname, gbdbFname, fixedFname)
        refreshPage("jobId=%d" % jobId, addNote=True)

    # show list of files is told to do so
    elif "showFiles" in args.keys() and "db" in args.keys():
        trackName = args["showFiles"].value
        tables, gbdbFiles = trackToFiles(trackName, trackTables, trackChildren, \
                tableSizes, tableToGbdbFiles, noTableTracks)

        print "<h4>MySQL tables linked to track %s</h4>" % trackName
        for table in tables:
            size = tableSizes[table]
            sizeStr = humanReadable(size)
            print table+" (%s) <br>" % sizeStr
        
        print "<h4>GBDB files linked to track %s</h4>" % trackName
        for gbdbFname in gbdbFiles:
            size = gbdbSizes[gbdbFname]
            sizeStr = humanReadable(size)
            print gbdbFname+" (%s) <br>" % sizeStr
        sys.exit(0)

    # if we have a jobId in URL, show the rsync log
    elif "jobId" in args.keys():
        if runningAtUcsc():
            print "cannot do this on hgwdev"
            sys.exit(0)

        jobId = int(args["jobId"].value)
        printLog(jobId)

    # stop job if requested to do so
    elif "stopAllJobs" in args.keys():
        stopAllJobs()
        print "All download jobs have been stopped<br>"
        print '<a href="hgMirror">Return to track selection</a>'
        sys.exit(0)

    # show tracklist and change default tracks if no param
    else:
        assertEmptyQueue()

        print '<h4>UCSC genome browser track download tool</h4>'
        htmlDbSelector(orgInfo, clade, org, db)

        showSubtracks = bool(int(args.getfirst("showSubtracks", "0")))

        localSizes = getLocalSizes(db)

        addPredefined(trackVis, superTracks, groupList, groupToTopTracks, trackLabels, trackChildren, \
            tableToGbdbFiles, trackTables, tableSizes)

        htmlTrackTable(db, trackLabels, trackTables, trackParents, trackChildren, \
            groupList, groupToTopTracks, \
            tableSizes, localSizes, gbdbSizes, tableToGbdbFiles, showSubtracks)

        postRsyncChanges(db, localSizes)

def main():
    # hide some tracks if any argument specified. makes this tool usable from command line, 
    # from cronjobs that only need to run this function
    if len(sys.argv)>1:
        postRsyncChanges("hg19", {"trackDb":1})
        sys.exit(0)

    print "Content-type: text/html"
    print

    parseHgConf()
    if hgConf==None or not hgConf.get("allowHgMirror", "0").lower() in ["1", "yes", "true"]:
        print("hgMirror is not activated on this machine<br>")
        print("Set allowHgMirror=1 in your cgi-bin/hg.conf file<br>")
        sys.exit(0)
        
    args = cgi.FieldStorage()

    if "debug" in args.keys():
        global DEBUG
        DEBUG = True

    htmlHeader()
    htmlMiddle(args)
    htmlFooter()

main()
